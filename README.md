# â—ˆ FLEET MIND
### Dual-USV Coordinated Patrol â€” Reinforcement Learning Game

A browser-based naval strategy game where two AI-powered unmanned surface
vehicles learn to coordinate patrol routes, maintain formation, and neutralize
threats using Proximal Policy Optimization (PPO).

---

## ðŸ—‚ Project Structure

```
fleet_mind/
â”œâ”€â”€ env/
â”‚   â””â”€â”€ dual_usv_env.py        â† Gymnasium RL environment
â”œâ”€â”€ train/
â”‚   â””â”€â”€ train_agents.py        â† PPO training + evaluation script
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ app.py                 â† Flask REST API (Render-ready)
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_env.py            â† Pytest environment tests
â”œâ”€â”€ logs/                      â† Auto-created during training
â”‚   â”œâ”€â”€ training_log.json
â”‚   â””â”€â”€ latest_replay.json
â”œâ”€â”€ models/                    â† Auto-created during training
â”‚   â””â”€â”€ dual_usv_ppo.zip
â”œâ”€â”€ fleet_mind.html            â† Frontend game (standalone)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ render.yaml                â† Render.com deployment config
â”œâ”€â”€ .env.example
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml             â† GitHub Actions CI
```

---

## ðŸš€ Quick Start (Local)

### 1. Clone & install
```bash
git clone https://github.com/YOUR_USERNAME/fleet-mind.git
cd fleet-mind
pip install -r requirements.txt
```

### 2. Set up environment variables
```bash
cp .env.example .env
# Edit .env and add your ANTHROPIC_API_KEY
```

### 3. Train the RL agents
```bash
# Full training run (takes ~10-20 min on CPU, ~3 min on GPU)
python train/train_agents.py --mode both --timesteps 300000

# Quick test run
python train/train_agents.py --mode both --timesteps 50000
```

### 4. Start the API
```bash
python backend/app.py
# â†’ Running on http://localhost:5000
```

### 5. Open the game
Open `fleet_mind.html` in your browser.
Set `API_BASE` in the HTML to `http://localhost:5000/api`.

---

## ðŸŒ Deploy to Render

### Step 1 â€” Push to GitHub
```bash
git init
git add .
git commit -m "Initial Fleet Mind commit"
git remote add origin https://github.com/YOUR_USERNAME/fleet-mind.git
git push -u origin main
```

### Step 2 â€” Create Render services
1. Go to [render.com](https://render.com) â†’ New â†’ Blueprint
2. Connect your GitHub repo
3. Render reads `render.yaml` and auto-creates:
   - **Web Service** â€” Flask API
   - **PostgreSQL** â€” Free database

### Step 3 â€” Add environment variables in Render dashboard
```
ANTHROPIC_API_KEY   â†’ your key from console.anthropic.com
SECRET_KEY          â†’ auto-generated by Render
DATABASE_URL        â†’ auto-set by Render PostgreSQL add-on
```

### Step 4 â€” Update the frontend
In `fleet_mind.html`, change:
```javascript
const API_BASE = "https://fleet-mind-api.onrender.com/api";
```

### Step 5 â€” Train & upload model
After the API is deployed, SSH into Render (paid plan) or run training
locally and upload `logs/latest_replay.json` to your repo.

---

## ðŸ§  RL Training Details

| Parameter | Value |
|---|---|
| Algorithm | PPO (Proximal Policy Optimization) |
| Policy | MlpPolicy (256 Ã— 256 hidden layers) |
| Observation space | 116 floats (positions, headings, threats, coverage grid) |
| Action space | MultiDiscrete([4, 4]) â€” 4 actions per USV |
| Max steps/episode | 500 |
| Learning rate | 3e-4 |
| Batch size | 64 |
| Recommended timesteps | 300,000 (fast) â€” 1,000,000 (optimal) |

### Reward Structure
| Event | Reward |
|---|---|
| New grid cell covered | +0.1 |
| Threat neutralized | +1.0 |
| Good formation (50â€“150m) | +0.2/step |
| Dispersed formation (>150m) | -0.25/step |
| Collision risk (<22m) | -0.6 |

---

## ðŸŽ® Game Modes

| Mode | Description |
|---|---|
| **Training** | Watch AI learn from scratch. Auto-advances episodes. |
| **Challenge** | Trained model deployed. You place threats. Scored. |
| **Commander** | You steer USV-Alpha (arrow keys). AI controls USV-Bravo. |

---

## ðŸ”Œ API Endpoints

| Method | Endpoint | Description |
|---|---|---|
| GET | `/api/health` | Service health check |
| GET | `/api/scores/leaderboard` | Top 10 scores |
| POST | `/api/scores/submit` | Submit a mission score |
| GET | `/api/replay/latest` | Get trained model replay |
| GET | `/api/training/stats` | Live training progress |
| GET | `/api/training/history` | Historical training chart data |
| POST | `/api/mission/new` | Generate new mission config |
| POST | `/api/narration` | Claude AI tactical narration |
| POST | `/api/debrief` | Claude AI mission debrief |

---

## ðŸ›  CAD Drawings

Top-down USV hull profiles were designed as SVG vector shapes embedded
directly in the game canvas. For custom CAD assets:
1. Design top-down vessel profile in FreeCAD or Fusion 360
2. Export as SVG
3. Replace the `drawUSV()` function in `fleet_mind.html` with your SVG path

---

## ðŸ“Š Tech Stack

| Layer | Technology |
|---|---|
| RL Training | Python + Stable-Baselines3 (PPO) + Gymnasium |
| Backend API | Flask + SQLAlchemy + Gunicorn |
| Database | PostgreSQL (Render) / SQLite (local dev) |
| AI Narration | Anthropic Claude API |
| Frontend | Vanilla HTML/CSS/JS + Canvas API |
| CI/CD | GitHub Actions â†’ Render auto-deploy |
| Hosting | Render.com (free tier) |

---

## ðŸ“ License
MIT â€” free to use, modify, and deploy.
